{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47277ccb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-huggingface in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (0.3.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from langchain-huggingface) (0.22.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.70 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from langchain-huggingface) (0.3.76)\n",
      "Requirement already satisfied: huggingface-hub>=0.33.4 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from langchain-huggingface) (0.34.4)\n",
      "Requirement already satisfied: requests in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2.32.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (6.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (4.13.2)\n",
      "Requirement already satisfied: filelock in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (3.19.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (25.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (4.64.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (1.1.10)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.11.5)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (9.1.2)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.27)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.28.1)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.24.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.1)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.33.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (2025.8.3)\n",
      "Requirement already satisfied: anyio in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2f56ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace,HuggingFaceEndpoint\n",
    "Access_Token=\"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\"\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    huggingfacehub_api_token=Access_Token,\n",
    "    temperature=0,\n",
    "    max_new_tokens=256\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "result = model.invoke(\"Who is the president of India?\")\n",
    "\n",
    "poem = model.invoke(\"write a 5 line poem on india cricket in bengali language\")\n",
    "print(result.content)\n",
    "print(poem.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ce962b",
   "metadata": {},
   "source": [
    "# EMBEDDING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7866b83c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.1.0-py3-none-any.whl (483 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m483.4/483.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Pillow in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (9.2.0)\n",
      "Requirement already satisfied: tqdm in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (4.64.1)\n",
      "Collecting transformers<5.0.0,>=4.41.0\n",
      "  Downloading transformers-4.56.1-py3-none-any.whl (11.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.20.0 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (0.34.4)\n",
      "Collecting torch>=1.11.0\n",
      "  Downloading torch-2.8.0-cp39-none-macosx_11_0_arm64.whl (73.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.1.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: scipy in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from sentence-transformers) (1.9.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: requests in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.28.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: filelock in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.12.0)\n",
      "Requirement already satisfied: jinja2 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (2.11.3)\n",
      "Requirement already satisfied: networkx in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers) (2.8.4)\n",
      "Collecting sympy>=1.13.3\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.7.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.21.5)\n",
      "Collecting safetensors>=0.4.3\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl (432 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m432.2/432.2 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3)\n",
      "Installing collected packages: sympy, safetensors, torch, transformers, sentence-transformers\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.10.1\n",
      "    Uninstalling sympy-1.10.1:\n",
      "      Successfully uninstalled sympy-1.10.1\n",
      "Successfully installed safetensors-0.6.2 sentence-transformers-5.1.0 sympy-1.14.0 torch-2.8.0 transformers-4.56.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a36c8b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding vector length: 384\n",
      "First 10 dimensions: [0.08242974430322647, -0.09008479118347168, -0.01371759083122015, 0.0036160468589514494, 0.013028830289840698, -0.06866682320833206, 0.049111589789390564, 0.04337377846240997, -0.06745374202728271, 0.008855975233018398]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Set your Hugging Face token as environment variable\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = Access_Token\n",
    "\n",
    "# 1. Create embedding model instance\n",
    "embedder = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    \n",
    ")\n",
    "\n",
    "# 2. Define your multiline string document\n",
    "doc = \"\"\"\n",
    "India is the seventh-largest country by land area and the most populous country in the world.\n",
    "Its capital is New Delhi, while Mumbai is the financial hub.\n",
    "The current president of India is Droupadi Murmu.\n",
    "\"\"\"\n",
    "\n",
    "# 3. Get embedding vector\n",
    "vector = embedder.embed_query(doc)\n",
    "\n",
    "# 4. Print results\n",
    "print(\"Embedding vector length:\", len(vector))\n",
    "print(\"First 10 dimensions:\", vector[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1e7a4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05774231 0.18418388 0.17049837 0.14744035 0.61838372]\n",
      "Query: tell me about bumrah\n",
      "Most similar document: Jasprit Bumrah is an Indian fast bowler known for his unorthodox action and yorkers.\n",
      "Similarity score: 0.6183837166641484\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Set your Hugging Face token as environment variable\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = Access_Token\n",
    "\n",
    "# Create the embedding model\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# List of documents\n",
    "documents = [\n",
    "    \"Virat Kohli is an Indian cricketer known for his aggressive batting and leadership.\",\n",
    "    \"MS Dhoni is a former Indian captain famous for his calm demeanor and finishing skills.\",\n",
    "    \"Sachin Tendulkar, also known as the 'God of Cricket', holds many batting records.\",\n",
    "    \"Rohit Sharma is known for his elegant batting and record-breaking double centuries.\",\n",
    "    \"Jasprit Bumrah is an Indian fast bowler known for his unorthodox action and yorkers.\"\n",
    "]\n",
    "\n",
    "# Query\n",
    "query = 'tell me about bumrah'\n",
    "\n",
    "# Generate embeddings\n",
    "doc_embeddings = embedding.embed_documents(documents)\n",
    "query_embedding = embedding.embed_query(query)\n",
    "\n",
    "#print(cosine_similarity([query_embedding], doc_embeddings))\n",
    "\n",
    "# Compute cosine similarity\n",
    "scores = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "print(scores)\n",
    "# Find the most similar document\n",
    "index, score = sorted(list(enumerate(scores)), key=lambda x: x[1])[-1]\n",
    "\n",
    "# Print results\n",
    "print(\"Query:\", query)\n",
    "print(\"Most similar document:\", documents[index])\n",
    "print(\"Similarity score:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ea22ce3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.49.1-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from streamlit) (6.1)\n",
      "Collecting protobuf<7,>=3.20\n",
      "  Downloading protobuf-6.32.1-cp39-abi3-macosx_10_9_universal2.whl (426 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.5/426.5 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gitpython!=3.1.19,<4,>=3.0.7\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.2/208.2 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tenacity<10,>=8.1.0 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from streamlit) (9.1.2)\n",
      "Collecting pydeck<1,>=0.8.0b4\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas<3,>=1.4.0 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from streamlit) (1.4.4)\n",
      "Collecting cachetools<7,>=4.0\n",
      "  Downloading cachetools-6.2.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from streamlit) (9.2.0)\n",
      "Collecting blinker<2,>=1.5.0\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Collecting numpy<3,>=1.23\n",
      "  Downloading numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl (5.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow>=7.0\n",
      "  Downloading pyarrow-21.0.0-cp39-cp39-macosx_12_0_arm64.whl (31.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.2/31.2 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging<26,>=20 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from streamlit) (25.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from streamlit) (4.13.2)\n",
      "Collecting altair!=5.4.0,!=5.4.1,<6,>=4.0\n",
      "  Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.2/731.2 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click<9,>=7.0 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from streamlit) (8.0.4)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from streamlit) (2.28.1)\n",
      "Collecting narwhals>=1.14.2\n",
      "  Downloading narwhals-2.5.0-py3-none-any.whl (407 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.3/407.3 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jsonschema>=3.0 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.16.0)\n",
      "Requirement already satisfied: jinja2 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.11.3)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from pandas<3,>=1.4.0->streamlit) (2022.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit) (2022.9.24)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.0.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (21.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/anindyadey/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Installing collected packages: smmap, pyarrow, protobuf, numpy, narwhals, cachetools, blinker, pydeck, gitdb, altair, gitpython, streamlit\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.5\n",
      "    Uninstalling numpy-1.21.5:\n",
      "      Successfully uninstalled numpy-1.21.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scipy 1.9.1 requires numpy<1.25.0,>=1.18.5, but you have numpy 2.0.2 which is incompatible.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 2.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed altair-5.5.0 blinker-1.9.0 cachetools-6.2.0 gitdb-4.0.12 gitpython-3.1.45 narwhals-2.5.0 numpy-2.0.2 protobuf-6.32.1 pyarrow-21.0.0 pydeck-0.9.1 smmap-5.0.2 streamlit-1.49.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6a1f74",
   "metadata": {},
   "source": [
    "# UI with Static Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d3ba0135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 16:58:31.279 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 16:58:31.280 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 16:58:31.282 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 16:58:31.283 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 16:58:31.284 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 16:58:31.285 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 16:58:31.286 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 16:58:31.288 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 16:58:31.289 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 16:58:31.289 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 16:58:31.290 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 16:58:31.291 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 16:58:31.291 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 16:58:31.292 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 16:58:31.292 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-24 16:58:31.292 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from langchain_huggingface import ChatHuggingFace,HuggingFaceEndpoint\n",
    "\n",
    "Access_Token=\"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\"\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    huggingfacehub_api_token=Access_Token,\n",
    "    temperature=0,\n",
    "    max_new_tokens=256\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "st.header('Research tool')\n",
    "\n",
    "user_input=st.text_input(\"Enter your Prompt\")\n",
    "if st.button('Submit'):\n",
    "    result=model.invoke(user_input)\n",
    "    st.write(result.content)\n",
    "    \n",
    "# Command to run --> streamlit run website.py [ARGUMENTS]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2b5481",
   "metadata": {},
   "source": [
    "# UI with Dynamic Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b2ffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from langchain_huggingface import ChatHuggingFace,HuggingFaceEndpoint\n",
    "from langchain_core.prompts import PromptTemplate,load_prompt\n",
    "\n",
    "Access_Token=\"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\"\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    huggingfacehub_api_token=Access_Token,\n",
    "    temperature=0,\n",
    "    max_new_tokens=256\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "st.header('Reasearch Tool')\n",
    "\n",
    "paper_input = st.selectbox( \"Select Research Paper Name\", [\"Attention Is All You Need\", \"BERT: Pre-training of Deep Bidirectional Transformers\", \"GPT-3: Language Models are Few-Shot Learners\", \"Diffusion Models Beat GANs on Image Synthesis\"] )\n",
    "\n",
    "style_input = st.selectbox( \"Select Explanation Style\", [\"Beginner-Friendly\", \"Technical\", \"Code-Oriented\", \"Mathematical\"] ) \n",
    "\n",
    "length_input = st.selectbox( \"Select Explanation Length\", [\"Short (1-2 paragraphs)\", \"Medium (3-5 paragraphs)\", \"Long (detailed explanation)\"] )\n",
    "\n",
    "\n",
    "\n",
    "# template\n",
    "template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "Please summarize the research paper titled \"{paper_input}\" with the following specifications:\n",
    "Explanation Style: {style_input}  \n",
    "Explanation Length: {length_input}  \n",
    "1. Mathematical Details:  \n",
    "   - Include relevant mathematical equations if present in the paper.  \n",
    "   - Explain the mathematical concepts using simple, intuitive code snippets where applicable.  \n",
    "2. Analogies:  \n",
    "   - Use relatable analogies to simplify complex ideas.  \n",
    "If certain information is not available in the paper, respond with: \"Insufficient information available\" instead of guessing.  \n",
    "Ensure the summary is clear, accurate, and aligned with the provided style and length.\n",
    "\"\"\",\n",
    "input_variables=['paper_input', 'style_input','length_input'],\n",
    "validate_template=True\n",
    ")\n",
    "\n",
    "#fill the Template\n",
    "prompt = template.invoke({\n",
    "        'paper_input':paper_input,\n",
    "        'style_input':style_input,\n",
    "        'length_input':length_input\n",
    "    })\n",
    "\n",
    "if st.button(\"Summaraize\"):\n",
    "    result=model.invoke(prompt)\n",
    "    st.write(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe07878",
   "metadata": {},
   "source": [
    "# SAVE THE TEMPLATE AS JSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a01310a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# template\n",
    "template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "Please summarize the research paper titled \"{paper_input}\" with the following specifications:\n",
    "Explanation Style: {style_input}  \n",
    "Explanation Length: {length_input}  \n",
    "1. Mathematical Details:  \n",
    "   - Include relevant mathematical equations if present in the paper.  \n",
    "   - Explain the mathematical concepts using simple, intuitive code snippets where applicable.  \n",
    "2. Analogies:  \n",
    "   - Use relatable analogies to simplify complex ideas.  \n",
    "If certain information is not available in the paper, respond with: \"Insufficient information available\" instead of guessing.  \n",
    "Ensure the summary is clear, accurate, and aligned with the provided style and length.\n",
    "\"\"\",\n",
    "input_variables=['paper_input', 'style_input','length_input'],\n",
    "validate_template=True\n",
    ")\n",
    "\n",
    "template.save('template.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12c64d4",
   "metadata": {},
   "source": [
    "# PASS THE TEMPLATE AS JSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6059b99b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-14 16:37:27.120 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-14 16:37:27.121 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-14 16:37:27.121 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-14 16:37:27.121 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-14 16:37:27.122 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-14 16:37:27.125 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-14 16:37:27.128 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-14 16:37:27.131 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-14 16:37:27.132 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-14 16:37:27.133 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-14 16:37:27.134 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-14 16:37:27.134 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-14 16:37:27.134 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-14 16:37:27.135 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-14 16:37:27.135 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-14 16:37:27.135 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-14 16:37:27.135 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-14 16:37:27.136 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-14 16:37:27.136 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-14 16:37:27.136 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-14 16:37:27.137 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-14 16:37:27.137 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-14 16:37:27.137 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-09-14 16:37:27.137 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m length_input \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mselectbox( \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelect Explanation Length\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShort (1-2 paragraphs)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMedium (3-5 paragraphs)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLong (detailed explanation)\u001b[39m\u001b[38;5;124m\"\u001b[39m] )\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# template\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m template\u001b[38;5;241m=\u001b[39m\u001b[43mload_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#fill the Template\u001b[39;00m\n\u001b[1;32m     29\u001b[0m prompt \u001b[38;5;241m=\u001b[39m template\u001b[38;5;241m.\u001b[39minvoke({\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpaper_input\u001b[39m\u001b[38;5;124m'\u001b[39m:paper_input,\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstyle_input\u001b[39m\u001b[38;5;124m'\u001b[39m:style_input,\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_input\u001b[39m\u001b[38;5;124m'\u001b[39m:length_input\n\u001b[1;32m     33\u001b[0m     })\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_core/prompts/loading.py:159\u001b[0m, in \u001b[0;36mload_prompt\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m    153\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading from the deprecated github-based Hub is no longer supported. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use the new LangChain Hub at https://smith.langchain.com/hub \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[0;32m--> 159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_prompt_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/langchain_core/prompts/loading.py:167\u001b[0m, in \u001b[0;36m_load_prompt_from_file\u001b[0;34m(file, encoding)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m\"\"\"Load prompt from file.\"\"\"\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Convert file to a Path object.\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Load from either json or yaml.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_path\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/pathlib.py:1082\u001b[0m, in \u001b[0;36mPath.__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m Path:\n\u001b[1;32m   1081\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m WindowsPath \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m PosixPath\n\u001b[0;32m-> 1082\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_parts\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flavour\u001b[38;5;241m.\u001b[39mis_supported:\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot instantiate \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m on your system\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1085\u001b[0m                               \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/pathlib.py:707\u001b[0m, in \u001b[0;36mPurePath._from_parts\u001b[0;34m(cls, args, init)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_parts\u001b[39m(\u001b[38;5;28mcls\u001b[39m, args, init\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;66;03m# We need to call _parse_args on the instance, so as to get the\u001b[39;00m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;66;03m# right flavour.\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m--> 707\u001b[0m     drv, root, parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drv \u001b[38;5;241m=\u001b[39m drv\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_root \u001b[38;5;241m=\u001b[39m root\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/pathlib.py:691\u001b[0m, in \u001b[0;36mPurePath._parse_args\u001b[0;34m(cls, args)\u001b[0m\n\u001b[1;32m    689\u001b[0m     parts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39m_parts\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 691\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    693\u001b[0m         \u001b[38;5;66;03m# Force-cast str subclasses to str (issue #21127)\u001b[39;00m\n\u001b[1;32m    694\u001b[0m         parts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(a))\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not method"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from langchain_huggingface import ChatHuggingFace,HuggingFaceEndpoint\n",
    "from langchain_core.prompts import PromptTemplate,load_prompt\n",
    "\n",
    "Access_Token=\"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\"\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    huggingfacehub_api_token=Access_Token,\n",
    "    temperature=0,\n",
    "    max_new_tokens=256\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "st.header('Reasearch Tool')\n",
    "\n",
    "paper_input = st.selectbox( \"Select Research Paper Name\", [\"Attention Is All You Need\", \"BERT: Pre-training of Deep Bidirectional Transformers\", \"GPT-3: Language Models are Few-Shot Learners\", \"Diffusion Models Beat GANs on Image Synthesis\"] )\n",
    "\n",
    "style_input = st.selectbox( \"Select Explanation Style\", [\"Beginner-Friendly\", \"Technical\", \"Code-Oriented\", \"Mathematical\"] ) \n",
    "\n",
    "length_input = st.selectbox( \"Select Explanation Length\", [\"Short (1-2 paragraphs)\", \"Medium (3-5 paragraphs)\", \"Long (detailed explanation)\"] )\n",
    "\n",
    "\n",
    "# template\n",
    "template=load_prompt(template.json)\n",
    "\n",
    "#fill the Template\n",
    "prompt = template.invoke({\n",
    "        'paper_input':paper_input,\n",
    "        'style_input':style_input,\n",
    "        'length_input':length_input\n",
    "    })\n",
    "\n",
    "if st.button(\"Summaraize\"):\n",
    "    result=model.invoke(prompt)\n",
    "    st.write(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9968b3",
   "metadata": {},
   "source": [
    "# CHATBOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa69dfd0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: HI\n",
      "AI:  How can I assist you today?\n",
      "You: What is the date today\n",
      "AI:  Today's date is September 14, 2024.\n",
      "You: multiply today date with 3\n",
      "AI:  Today's date is 2024-09-14. \n",
      "\n",
      "To multiply 2024-09-14 with 3, we'll do the following conversions:\n",
      "- Year: 2024 * 3 = 6072\n",
      "- Month and Day: (2023*3) +1 in the month and (14*3) = (6072 + 9 +14) % 12 in the month,\n",
      "- Month and Day = 6095 % 12 =6 * 12 + 5,  (46 * 12 + 11 )  which is the converted month (10 then convert to string) and day (12 then convert to string) are 10 month (string) with the format  \"0\" before the single digit month will give us '10', then day '12'( the format  \"0\" before the single digit will also give us '12'(12). Therefore year is '6072', month is '010' and day is '012'.\n",
      "You: which is bigger number 3 or 5\n",
      "AI:  The number 5 is bigger than 3.\n",
      "You: multiply bigger number with 3\n",
      "AI:  I'll multiply 1000 (a bigger number) with 3.\n",
      "\n",
      "1000 * 3 = 3000\n",
      "You: exit\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import ChatHuggingFace,HuggingFaceEndpoint\n",
    "\n",
    "Access_Token=\"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\"\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    huggingfacehub_api_token=Access_Token,\n",
    "    temperature=0,\n",
    "    max_new_tokens=256\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "while True:\n",
    "    user_input = input('You: ')\n",
    "    if user_input == 'exit':\n",
    "        break\n",
    "    result = model.invoke(user_input)\n",
    "    print(\"AI: \",result.content)\n",
    "                     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e449e1c",
   "metadata": {},
   "source": [
    "# CHATBOT with Context of Previous Messege(CHAT HISTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a908a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: how was the day\n",
      "AI:  This conversation just started, so I don't have any prior knowledge of a day. I'm a large language model, I don't have personal experiences or memories, but I'm here to help you with any questions or topics you'd like to discuss. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import ChatHuggingFace,HuggingFaceEndpoint\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "Access_Token=\"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\"\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    huggingfacehub_api_token=Access_Token,\n",
    "    temperature=0,\n",
    "    max_new_tokens=256\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "\n",
    "chat_history = [\n",
    "    SystemMessage(content='You are a helpful AI assistant')\n",
    "]\n",
    "\n",
    "\n",
    "while True:\n",
    "    user_input = input('You: ')\n",
    "    chat_history.append(HumanMessage(content=user_input))\n",
    "    if user_input == 'exit':\n",
    "        break\n",
    "    result = model.invoke(chat_history)\n",
    "    chat_history.append(AIMessage(content=result.content))\n",
    "    print(\"AI: \",result.content)\n",
    "\n",
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439cd8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
